{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting librosa\n",
      "  Using cached librosa-0.10.0.post2-py3-none-any.whl (253 kB)\n",
      "Collecting lazy-loader>=0.1\n",
      "  Using cached lazy_loader-0.2-py3-none-any.whl (8.6 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\user\\anaconda31\\lib\\site-packages (from librosa) (1.0.2)\n",
      "Collecting pooch<1.7,>=1.0\n",
      "  Using cached pooch-1.6.0-py3-none-any.whl (56 kB)\n",
      "Collecting soundfile>=0.12.1\n",
      "  Using cached soundfile-0.12.1-py2.py3-none-win_amd64.whl (1.0 MB)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\user\\anaconda31\\lib\\site-packages (from librosa) (0.55.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\user\\anaconda31\\lib\\site-packages (from librosa) (4.3.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\user\\anaconda31\\lib\\site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\user\\anaconda31\\lib\\site-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\user\\anaconda31\\lib\\site-packages (from librosa) (1.0.3)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\user\\anaconda31\\lib\\site-packages (from librosa) (1.9.1)\n",
      "Collecting audioread>=2.1.9\n",
      "  Using cached audioread-3.0.0-py3-none-any.whl\n",
      "Collecting soxr>=0.3.2\n",
      "  Using cached soxr-0.3.5-cp39-cp39-win_amd64.whl (184 kB)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in c:\\users\\user\\anaconda31\\lib\\site-packages (from librosa) (1.21.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda31\\lib\\site-packages (from numba>=0.51.0->librosa) (63.4.1)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in c:\\users\\user\\anaconda31\\lib\\site-packages (from numba>=0.51.0->librosa) (0.38.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\user\\anaconda31\\lib\\site-packages (from pooch<1.7,>=1.0->librosa) (2.28.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda31\\lib\\site-packages (from pooch<1.7,>=1.0->librosa) (21.3)\n",
      "Requirement already satisfied: appdirs>=1.3.0 in c:\\users\\user\\anaconda31\\lib\\site-packages (from pooch<1.7,>=1.0->librosa) (1.4.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\anaconda31\\lib\\site-packages (from scikit-learn>=0.20.0->librosa) (2.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\user\\anaconda31\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\user\\anaconda31\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\user\\anaconda31\\lib\\site-packages (from packaging>=20.0->pooch<1.7,>=1.0->librosa) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda31\\lib\\site-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\user\\anaconda31\\lib\\site-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\anaconda31\\lib\\site-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda31\\lib\\site-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (3.3)\n",
      "Installing collected packages: soxr, lazy-loader, audioread, soundfile, pooch, librosa\n",
      "Successfully installed audioread-3.0.0 lazy-loader-0.2 librosa-0.10.0.post2 pooch-1.6.0 soundfile-0.12.1 soxr-0.3.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install librosa\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "資料資訊\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 28 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   ID                         1000 non-null   object \n",
      " 1   Sex                        1000 non-null   int64  \n",
      " 2   Age                        1000 non-null   int64  \n",
      " 3   Disease category           1000 non-null   int64  \n",
      " 4   Narrow pitch range         1000 non-null   int64  \n",
      " 5   Decreased volume           1000 non-null   int64  \n",
      " 6   Fatigue                    1000 non-null   int64  \n",
      " 7   Dryness                    1000 non-null   int64  \n",
      " 8   Lumping                    1000 non-null   int64  \n",
      " 9   heartburn                  1000 non-null   int64  \n",
      " 10  Choking                    1000 non-null   int64  \n",
      " 11  Eye dryness                1000 non-null   int64  \n",
      " 12  PND                        1000 non-null   int64  \n",
      " 13  Smoking                    1000 non-null   int64  \n",
      " 14  PPD                        184 non-null    float64\n",
      " 15  Drinking                   1000 non-null   int64  \n",
      " 16  frequency                  1000 non-null   int64  \n",
      " 17  Diurnal pattern            1000 non-null   int64  \n",
      " 18  Onset of dysphonia         1000 non-null   int64  \n",
      " 19  Noise at work              1000 non-null   int64  \n",
      " 20  Occupational vocal demand  1000 non-null   int64  \n",
      " 21  Diabetes                   1000 non-null   int64  \n",
      " 22  Hypertension               1000 non-null   int64  \n",
      " 23  CAD                        1000 non-null   int64  \n",
      " 24  Head and Neck Cancer       1000 non-null   int64  \n",
      " 25  Head injury                1000 non-null   int64  \n",
      " 26  CVA                        1000 non-null   int64  \n",
      " 27  Voice handicap index - 10  993 non-null    float64\n",
      "dtypes: float64(2), int64(25), object(1)\n",
      "memory usage: 218.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# 資料判斷\n",
    "df_csv = pd.read_csv(\"Training Dataset/training datalist.csv\")\n",
    "print(\"資料資訊\")\n",
    "df_csv.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disease category in source_df : [1 2 3 5 4]\n",
      "source_df :\n",
      " ./Training Dataset/training_voice_data1202f15.wav\n"
     ]
    }
   ],
   "source": [
    "# 挑選出要訓練的Disease category 1、2、3\n",
    "df_csv = df_csv.loc[df_csv['Disease category'].isin([1, 2, 3, 4, 5]), ['ID', 'Disease category']]\n",
    "\n",
    "# 在dataframe中加入要訓練的音檔路徑\n",
    "df_csv['wav_path'] = df_csv['ID'].map(\"./Training Dataset/training_voice_data{}.wav\".format)\n",
    "\n",
    "print(\"Disease category in source_df :\",df_csv['Disease category'].unique())\n",
    "print(\"source_df :\\n\", df_csv[\"wav_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1000 entries, 0 to 999\n",
      "Data columns (total 3 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   ID                1000 non-null   object\n",
      " 1   Disease category  1000 non-null   int64 \n",
      " 2   wav_path          1000 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 63.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_csv.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_df shape : (800, 3) , test_df shape : (200, 3)\n",
      "./Training Dataset/training_voice_data1202f15.wav\n"
     ]
    }
   ],
   "source": [
    "training_df, test_df = train_test_split(df_csv, test_size=0.2, random_state=333)\n",
    "\n",
    "print(\"training_df shape :\", training_df.shape, \", test_df shape :\", test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義函數\n",
    "def audio_to_mfccs(filename, sample_rate=44100, offset=0, duration=None):\n",
    "    # 讀取音訊檔案，並設定取樣率、起始時間、及持續時間\n",
    "    voice, sample_rate = librosa.load(\n",
    "        filename, sr=sample_rate, offset=offset, duration=duration\n",
    "    )\n",
    "\n",
    "    # 將時間值轉換為 FFT 與 hop length 所需的框架數 (以取樣點表示)\n",
    "    n_fft = int(16/1000 * sample_rate)  # 將 16 毫秒轉換為取樣點\n",
    "    hop_length = int(8/1000 * sample_rate)  # 將 8 毫秒轉換為取樣點\n",
    "\n",
    "    # 計算音訊數據的 MFCC 特徵\n",
    "    mfcc_feature = librosa.feature.mfcc(\n",
    "        y=voice, sr=sample_rate, n_mfcc=13, n_fft=n_fft, hop_length=hop_length)\n",
    "\n",
    "    # 計算 MFCC 的一階和二階差分特徵\n",
    "    delta_mfcc_feature = librosa.feature.delta(mfcc_feature)\n",
    "\n",
    "    # 將原始 MFCC 特徵和差分特徵串聯起來，得到所有幀的特徵向量\n",
    "    mfccs = np.concatenate((mfcc_feature, delta_mfcc_feature))\n",
    "    mfccs_features = np.transpose(mfccs)  # 將矩陣轉置，使每行代表一個幀\n",
    "\n",
    "    # 返回特徵向量\n",
    "    return mfccs_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-48ecd02d900e>:4: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  voice, sample_rate = librosa.load(\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './Training Dataset/training_voice_data1101uri.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\noga1\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr_native\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__soundfile_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\noga1\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36m__soundfile_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;31m# Otherwise, create the soundfile object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[0mcontext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSoundFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\noga1\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\soundfile.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[0;32m    657\u001b[0m                                          format, subtype, endian)\n\u001b[1;32m--> 658\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    659\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missuperset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'r+'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseekable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\noga1\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\soundfile.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_snd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msf_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mLibsndfileError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Error opening {0!r}: \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode_int\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_snd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSFM_WRITE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLibsndfileError\u001b[0m: Error opening './Training Dataset/training_voice_data1101uri.wav': System error.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-383709b7865e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtraining_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mid\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtraining_id\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mmfccs_feature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maudio_to_mfccs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtraining_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ID'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'wav_path'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmfccs_feature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# print(\"id :\",id, \", number of frames :\", df.shape[0])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-48ecd02d900e>\u001b[0m in \u001b[0;36maudio_to_mfccs\u001b[1;34m(filename, sample_rate, offset, duration)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0maudio_to_mfccs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m44100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# 讀取音訊檔案，並設定取樣率、起始時間、及持續時間\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     voice, sample_rate = librosa.load(\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moffset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mduration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     )\n",
      "\u001b[1;32mc:\\Users\\noga1\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    182\u001b[0m                     \u001b[1;34m\"PySoundFile failed. Trying audioread instead.\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m                 )\n\u001b[1;32m--> 184\u001b[1;33m                 \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr_native\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__audioread_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-119>\u001b[0m in \u001b[0;36m__audioread_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\noga1\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\librosa\\util\\decorators.py\u001b[0m in \u001b[0;36m__wrapper\u001b[1;34m(func, *args, **kwargs)\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Would be 2, but the decorator adds a level\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         )\n\u001b[1;32m---> 60\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__wrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\noga1\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36m__audioread_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[0;32m    239\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[1;31m# If the input was not an audioread object, try to open it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m         \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maudioread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maudio_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mreader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0minput_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\noga1\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\audioread\\__init__.py\u001b[0m in \u001b[0;36maudio_open\u001b[1;34m(path, backends)\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mBackendClass\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbackends\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mBackendClass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mDecodeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\noga1\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\audioread\\rawread.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \"\"\"\n\u001b[0;32m     58\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './Training Dataset/training_voice_data1101uri.wav'"
     ]
    }
   ],
   "source": [
    "training_id = training_df['ID'].tolist()\n",
    "training_data = pd.DataFrame()\n",
    "for id in training_id:\n",
    "    mfccs_feature = audio_to_mfccs(training_df[training_df['ID']==id]['wav_path'].values[0])\n",
    "    df = pd.DataFrame(mfccs_feature)\n",
    "    # print(\"id :\",id, \", number of frames :\", df.shape[0])\n",
    "\n",
    "    # 訓練資料標記\n",
    "    label = training_df[training_df['ID']==id]['Disease category'].values[0]\n",
    "    if label==1:\n",
    "        df['c1'] = 1; df['c2'] = 0; df['c3'] = 0 ; df['c4'] = 0; df['c5'] = 0\n",
    "    elif label==2:\n",
    "        df['c1'] = 0; df['c2'] = 1; df['c3'] = 0 ; df['c4'] = 0; df['c5'] = 0\n",
    "    elif label==3:\n",
    "        df['c1'] = 0; df['c2'] = 0; df['c3'] = 1 ; df['c4'] = 0; df['c5'] = 0\n",
    "    elif label==4:\n",
    "        df['c1'] = 0; df['c2'] = 0; df['c3'] = 0 ; df['c4'] = 1; df['c5'] = 0\n",
    "    elif label==5:\n",
    "        df['c1'] = 0; df['c2'] = 0; df['c3'] = 0 ; df['c4'] = 0; df['c5'] = 1\n",
    "    else:\n",
    "        df['c1'] = np.nan; df['c2'] = np.nan; df['c3'] = np.nan; df['c4'] = np.nan; df['c5'] = np.nan\n",
    "\n",
    "    training_data = pd.concat([training_data, df])\n",
    "\n",
    "print(\"training_data.shape :\", training_data.shape)\n",
    "\n",
    "x_train = training_data.iloc[:, :-5]\n",
    "y_train = training_data.iloc[:, -5:]\n",
    "print(\"x_train.shape, y_train.shape :\", x_train.shape, y_train.shape)\n",
    "print(\"y_train.columns :\", y_train.columns.tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"Bmpu6ph00f8a"},"source":["# 載入套件"]},{"cell_type":"code","execution_count":44,"metadata":{"executionInfo":{"elapsed":3201,"status":"ok","timestamp":1679112633445,"user":{"displayName":"Nien-Ting Lee","userId":"13054204329208761386"},"user_tz":-480},"id":"L-ZQpiZ20f8c"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import librosa\n","\n","from sklearn.model_selection import train_test_split\n","from scipy.stats import skew\n","\n","from sklearn.multiclass import  OneVsOneClassifier\n","from sklearn.svm import LinearSVC\n","from sklearn.pipeline import make_pipeline\n","from sklearn.svm import SVC\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.multiclass import OneVsOneClassifier\n","\n","\n","import tensorflow as tf\n","from tensorflow.keras.layers import Activation, BatchNormalization, Dense, LayerNormalization\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, recall_score"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"t6rc2EnF0f8d"},"source":["# 載入訓練資料"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":339,"status":"ok","timestamp":1679112779630,"user":{"displayName":"Nien-Ting Lee","userId":"13054204329208761386"},"user_tz":-480},"id":"GBVn5Rft0f8d","outputId":"feea3961-8d4d-45d2-c089-7d993ddcb979"},"outputs":[{"name":"stdout","output_type":"stream","text":["資料資訊\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 1000 entries, 0 to 999\n","Data columns (total 28 columns):\n"," #   Column                     Non-Null Count  Dtype  \n","---  ------                     --------------  -----  \n"," 0   ID                         1000 non-null   object \n"," 1   Sex                        1000 non-null   int64  \n"," 2   Age                        1000 non-null   int64  \n"," 3   Disease category           1000 non-null   int64  \n"," 4   Narrow pitch range         1000 non-null   int64  \n"," 5   Decreased volume           1000 non-null   int64  \n"," 6   Fatigue                    1000 non-null   int64  \n"," 7   Dryness                    1000 non-null   int64  \n"," 8   Lumping                    1000 non-null   int64  \n"," 9   heartburn                  1000 non-null   int64  \n"," 10  Choking                    1000 non-null   int64  \n"," 11  Eye dryness                1000 non-null   int64  \n"," 12  PND                        1000 non-null   int64  \n"," 13  Smoking                    1000 non-null   int64  \n"," 14  PPD                        184 non-null    float64\n"," 15  Drinking                   1000 non-null   int64  \n"," 16  frequency                  1000 non-null   int64  \n"," 17  Diurnal pattern            1000 non-null   int64  \n"," 18  Onset of dysphonia         1000 non-null   int64  \n"," 19  Noise at work              1000 non-null   int64  \n"," 20  Occupational vocal demand  1000 non-null   int64  \n"," 21  Diabetes                   1000 non-null   int64  \n"," 22  Hypertension               1000 non-null   int64  \n"," 23  CAD                        1000 non-null   int64  \n"," 24  Head and Neck Cancer       1000 non-null   int64  \n"," 25  Head injury                1000 non-null   int64  \n"," 26  CVA                        1000 non-null   int64  \n"," 27  Voice handicap index - 10  993 non-null    float64\n","dtypes: float64(2), int64(25), object(1)\n","memory usage: 218.9+ KB\n"]}],"source":["# 資料判斷\n","df_csv = pd.read_csv(\"Training Dataset/training datalist.csv\")\n","print(\"資料資訊\")\n","df_csv.info()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"L6Lwo9Sb0f8e"},"source":["# 資料前處理"]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":261,"status":"ok","timestamp":1679112868535,"user":{"displayName":"Nien-Ting Lee","userId":"13054204329208761386"},"user_tz":-480},"id":"ql3TRu1c0f8e","outputId":"ee5484b2-c262-42c0-87ea-75e83fa9dc21"},"outputs":[{"name":"stdout","output_type":"stream","text":["Disease category in source_df : [1 2 3 5 4]\n","source_df :\n"," 0      ./Training Dataset/training_voice_data/1202f15...\n","1      ./Training Dataset/training_voice_data/0600ve0...\n","2      ./Training Dataset/training_voice_data/1001o7l...\n","3      ./Training Dataset/training_voice_data/1201c1t...\n","4      ./Training Dataset/training_voice_data/0402jvt...\n","                             ...                        \n","995    ./Training Dataset/training_voice_data/0G00ftn...\n","996    ./Training Dataset/training_voice_data/1201pkr...\n","997    ./Training Dataset/training_voice_data/0202p64...\n","998    ./Training Dataset/training_voice_data/12021au...\n","999    ./Training Dataset/training_voice_data/04027it...\n","Name: wav_path, Length: 1000, dtype: object\n"]}],"source":["# 挑選出要訓練的Disease category 1、2、3、4、5\n","df_csv = df_csv.loc[df_csv['Disease category'].isin([1, 2, 3, 4, 5]), ['ID', 'Disease category']]\n","\n","# 在dataframe中加入要訓練的音檔路徑\n","df_csv['wav_path'] = df_csv['ID'].map(\"./Training Dataset/training_voice_data/{}.wav\".format)\n","\n","print(\"Disease category in source_df :\",df_csv['Disease category'].unique())\n","print(\"source_df :\\n\", df_csv[\"wav_path\"])"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"_V-MWxQ00f8e"},"source":["# 訓練聲學特徵"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"WmrumsJL0f8f"},"source":["## 聲學音檔轉換MFCC特徵與訓練"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[],"source":["# 定義函數\n","def audio_to_mfccs(filename, sample_rate=44100, offset=0, duration=None):\n","    # 讀取音訊檔案，並設定取樣率、起始時間、及持續時間\n","    voice, sample_rate = librosa.load(\n","        filename, sr=sample_rate, offset=offset, duration=duration\n","    )\n","\n","    # 將時間值轉換為 FFT 與 hop length 所需的框架數 (以取樣點表示)\n","    n_fft = int(16/1000 * sample_rate)  # 將 16 毫秒轉換為取樣點\n","    hop_length = int(8/1000 * sample_rate)  # 將 8 毫秒轉換為取樣點\n","\n","    # 計算音訊數據的 MFCC 特徵\n","    mfcc_feature = librosa.feature.mfcc(\n","        y=voice, sr=sample_rate, n_mfcc=13, n_fft=n_fft, hop_length=hop_length)\n","\n","    # 計算 MFCC 的一階和二階差分特徵\n","    delta_mfcc_feature = librosa.feature.delta(mfcc_feature)\n","\n","    # 將原始 MFCC 特徵和差分特徵串聯起來，得到所有幀的特徵向量\n","    mfccs = np.concatenate((mfcc_feature, delta_mfcc_feature))\n","    mfccs_features = np.transpose(mfccs)  # 將矩陣轉置，使每行代表一個幀\n","\n","    # 返回特徵向量\n","    return mfccs_features"]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":230171,"status":"ok","timestamp":1679113103587,"user":{"displayName":"Nien-Ting Lee","userId":"13054204329208761386"},"user_tz":-480},"id":"ZsbSG_s00f8f","outputId":"354c5beb-05df-4ff5-fc22-bbe017685b25"},"outputs":[{"name":"stdout","output_type":"stream","text":["training_data.shape : (1000, 31)\n","x_train.shape, y_train.shape : (1000, 26) (1000, 5)\n","y_train.columns : ['c1', 'c2', 'c3', 'c4', 'c5']\n"]}],"source":["training_id = df_csv['ID'].tolist()\n","training_data = pd.DataFrame()\n","for id in training_id:\n","    \n","    mfccs_feature = audio_to_mfccs(df_csv[df_csv['ID']==id]['wav_path'].values[0])\n","    df = pd.DataFrame()\n","    for i in range(26):\n","        df_i = pd.DataFrame(np.array(mfccs_feature[0][i]).reshape(1,-1))\n","        df = pd.concat([df, df_i], axis=1)\n","        \n","    # print(\"id :\",id, \", number of frames :\", df.shape[0])\n","    # 訓練資料標記\n","    label = df_csv[df_csv['ID']==id]['Disease category'].values[0]\n","    if label==1:\n","        df['c1'] = 1; df['c2'] = 0; df['c3'] = 0 ; df['c4'] = 0; df['c5'] = 0\n","    elif label==2:\n","        df['c1'] = 0; df['c2'] = 1; df['c3'] = 0 ; df['c4'] = 0; df['c5'] = 0\n","    elif label==3:\n","        df['c1'] = 0; df['c2'] = 0; df['c3'] = 1 ; df['c4'] = 0; df['c5'] = 0\n","    elif label==4:\n","        df['c1'] = 0; df['c2'] = 0; df['c3'] = 0 ; df['c4'] = 1; df['c5'] = 0\n","    elif label==5:\n","        df['c1'] = 0; df['c2'] = 0; df['c3'] = 0 ; df['c4'] = 0; df['c5'] = 1\n","    else:\n","        df['c1'] = np.nan; df['c2'] = np.nan; df['c3'] = np.nan; df['c4'] = np.nan; df['c5'] = np.nan\n","\n","    training_data = pd.concat([training_data, df])\n","    \n","print(\"training_data.shape :\", training_data.shape)\n","\n","x_train = training_data.iloc[:, :-5]\n","y_train = training_data.iloc[:, -5:]\n","print(\"x_train.shape, y_train.shape :\", x_train.shape, y_train.shape)\n","print(\"y_train.columns :\", y_train.columns.tolist())"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["轉成numpy矩陣"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[-5.53074524e+02  1.48494080e+02  1.46729660e+01 ... -3.93367976e-01\n","  -3.19579206e-02  1.06491983e+00]\n"," [-2.22018585e+02  1.32414246e+02 -1.35683060e+00 ... -9.75926936e-01\n","  -3.62859637e-01  6.54560566e-01]\n"," [-3.39410553e+02  1.86702805e+02 -2.79492817e+01 ... -4.88830119e-01\n","  -7.36986995e-01  4.74724650e-01]\n"," ...\n"," [-2.79279510e+02  1.13782791e+02 -2.01488895e+01 ... -6.52139187e-01\n","  -1.33095014e+00  1.11008868e-01]\n"," [-4.17048859e+02  1.23644379e+02  3.54444265e+00 ... -1.04734026e-01\n","   1.49622679e+00 -7.80113876e-01]\n"," [-3.73614166e+02  1.93103134e+02  2.38179951e+01 ...  3.70338380e-01\n","   1.18615009e-01  1.16457713e+00]]\n","[[1 0 0 0 0]\n"," [0 1 0 0 0]\n"," [0 1 0 0 0]\n"," ...\n"," [0 0 1 0 0]\n"," [0 1 0 0 0]\n"," [0 1 0 0 0]]\n"]}],"source":["x_num = x_train.to_numpy()\n","y_num = y_train.to_numpy()\n","\n","print(x_num)\n","print(y_num)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["將y的0~4類轉成1~5類"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[],"source":["for i in range(len(y_num)):\n","    y_num[i] += 1"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 訓練與驗證資料切分"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["training_x shape : (800, 26) , x_test shape : (200, 26)\n","training_y shape : (800, 5) , y_test shape : (200, 5)\n"]}],"source":["\n","training_x, x_test ,training_y, y_test = train_test_split(x_num, y_num, test_size=0.2, random_state=42)\n","print(\"training_x shape :\", training_x.shape, \", x_test shape :\", x_test.shape)\n","print(\"training_y shape :\", training_y.shape, \", y_test shape :\", y_test.shape)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# 模型架構"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["我做的"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[],"source":["# 在 Keras 裡面我們可以很簡單的使用 Sequential 的方法建建立一個 Model\n","model = Sequential()\n","# 加入 hidden layer-1 of 78 neurons 指定 input_dim 為 26  (有 26 個特徵)\n","model.add(Dense(78, input_dim=26))\n","# 使用 'sigmoid' 當作 activation function\n","model.add(Activation('relu'))\n","# 加入 hidden layer-2 of 256 neurons\n","model.add(Dense(52))\n","# 使用 'sigmoid' 當作 activation function\n","model.add(Activation('relu'))\n","# 加入 hidden layer-3 of 128 neurons\n","model.add(Dense(26))\n","# 使用 'sigmoid' 當作 activation function\n","model.add(Activation('relu'))\n","# 加入 output layer of 10 neurons\n","model.add(Dense(5))\n","# 使用 'softmax' 當作 activation function\n","model.add(Activation('softmax'))"]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","15/15 - 0s - loss: 120.5592 - accuracy: 0.2389 - val_loss: 211.6860 - val_accuracy: 0.1875 - 390ms/epoch - 26ms/step\n","Epoch 2/10\n","15/15 - 0s - loss: 320.1971 - accuracy: 0.2306 - val_loss: 532.0271 - val_accuracy: 0.1750 - 30ms/epoch - 2ms/step\n","Epoch 3/10\n","15/15 - 0s - loss: 733.4626 - accuracy: 0.2306 - val_loss: 1150.9713 - val_accuracy: 0.1750 - 32ms/epoch - 2ms/step\n","Epoch 4/10\n","15/15 - 0s - loss: 1487.3677 - accuracy: 0.2306 - val_loss: 2229.3101 - val_accuracy: 0.1750 - 32ms/epoch - 2ms/step\n","Epoch 5/10\n","15/15 - 0s - loss: 2770.6150 - accuracy: 0.2306 - val_loss: 3993.2988 - val_accuracy: 0.1750 - 30ms/epoch - 2ms/step\n","Epoch 6/10\n","15/15 - 0s - loss: 4780.9497 - accuracy: 0.2306 - val_loss: 6686.6143 - val_accuracy: 0.1750 - 32ms/epoch - 2ms/step\n","Epoch 7/10\n","15/15 - 0s - loss: 7817.0693 - accuracy: 0.2306 - val_loss: 10599.9365 - val_accuracy: 0.1750 - 33ms/epoch - 2ms/step\n","Epoch 8/10\n","15/15 - 0s - loss: 12091.6338 - accuracy: 0.2306 - val_loss: 15997.0654 - val_accuracy: 0.1750 - 35ms/epoch - 2ms/step\n","Epoch 9/10\n","15/15 - 0s - loss: 17946.8496 - accuracy: 0.2306 - val_loss: 23247.0898 - val_accuracy: 0.1750 - 33ms/epoch - 2ms/step\n","Epoch 10/10\n","15/15 - 0s - loss: 25675.7148 - accuracy: 0.2306 - val_loss: 32663.1133 - val_accuracy: 0.1750 - 31ms/epoch - 2ms/step\n"]}],"source":["# 定義訓練方式  \n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# 開始訓練  \n","train_results = model.fit(x=training_x,  \n","                          y=training_y, validation_split=0.1,  \n","                          epochs=10, batch_size=50, verbose=2)  "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["demo的"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["MODEL_SAVE_NAME = \"AI_CUP_acoustic_sample_model\"\n","\n","# default hyperparameters\n","NEURONS = 300\n","HIDDEN_LAYERS = 3\n","\n","def create_DNN(input_shape, neurons = NEURONS, hidden_layers = HIDDEN_LAYERS, learning_rate = 0.001, verbose=0):\n","    model = Sequential()\n","\n","    model.add(Dense(neurons, input_dim=input_shape))\n","    model.add(Activation('sigmoid'))\n","\n","    for i in range(hidden_layers-1):\n","        model.add(Dense(neurons))\n","        model.add(Activation('sigmoid'))\n","        # model.add(Dropout(0.5))\n","\n","    model.add(Dense(5))\n","    model.add(Activation('softmax'))\n","\n","    opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n","    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n","\n","    if verbose:\n","        model.summary()\n","    \n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3816,"status":"ok","timestamp":1679113216440,"user":{"displayName":"Nien-Ting Lee","userId":"13054204329208761386"},"user_tz":-480},"id":"DmergrL60f8g","outputId":"e00684fa-4304-411c-ca26-378f9b1db63d"},"outputs":[],"source":["model = create_DNN(input_shape = training_x.shape[1], verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":171382,"status":"ok","timestamp":1679113387820,"user":{"displayName":"Nien-Ting Lee","userId":"13054204329208761386"},"user_tz":-480},"id":"fp0QVZKV0f8g","outputId":"703410cc-02f0-4319-9093-75c9ce1c95c6"},"outputs":[],"source":["train_results = model.fit(training_x, training_y, batch_size=10, epochs=50, \n","                            callbacks=[EarlyStopping(monitor='val_loss', patience=5, mode='auto'),\n","                                        ModelCheckpoint(MODEL_SAVE_NAME+\".h5\", save_best_only=True)], \n","                            validation_data=(x_num, y_num))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Z9QcyHge0f8g"},"source":["## 訓練資料預測結果"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":173879,"status":"ok","timestamp":1679113561697,"user":{"displayName":"Nien-Ting Lee","userId":"13054204329208761386"},"user_tz":-480},"id":"SU-bPinv0f8g","outputId":"d39a52df-eac1-43fc-fcef-30e647b36fc7"},"outputs":[],"source":["y_true = training_df['Disease category'] - 1  # 將[1,2,3]轉換為[0,1,2]\n","y_pred = []\n","for id in training_id:\n","    mfccs_feature = audio_to_mfccs(training_df[training_df['ID']==id]['wav_path'].values[0])\n","    df = pd.DataFrame(mfccs_feature)\n","\n","    frame_pred = model.predict(df)\n","    frame_pred_results = frame_pred.argmax(axis=1)\n","\n","    person_pred = np.array([np.sum(frame_pred_results==0), np.sum(frame_pred_results==1), np.sum(frame_pred_results==2)]).argmax()  # 注意!如三類別相同票數，預測會為0\n","\n","    y_pred.append(person_pred)\n","\n","results_recall = recall_score(y_true, y_pred, average=None)\n","print(\"Training UAR(Unweighted Average Recall) :\", results_recall.mean())\n","\n","ConfusionMatrixDisplay(confusion_matrix(y_true, y_pred)).plot(cmap='Blues')"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"B10Wk9QP0f8g"},"source":["# 驗證資料測試結果"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WzR8pEBO0f8h","outputId":"13b09f37-57cc-42fd-e527-b0baca8d6559"},"outputs":[],"source":["# model = load_model(MODEL_SAVE_NAME + \".h5\")\n","\n","y_true = test_df['Disease category'] - 1  # 將[1,2,3]轉換為[0,1,2]\n","y_pred = []\n","for id in test_df['ID'].tolist():\n","    mfccs_feature = audio_to_mfccs(test_df[test_df['ID']==id]['wav_path'].values[0])\n","    df = pd.DataFrame(mfccs_feature)\n","\n","    frame_pred = model.predict(df)\n","    frame_pred_results = frame_pred.argmax(axis=1)\n","\n","    person_pred = np.array([np.sum(frame_pred_results==0), np.sum(frame_pred_results==1), np.sum(frame_pred_results==2)]).argmax()  # 注意!如三類別相同票數，預測會為0\n","\n","    y_pred.append(person_pred)\n","    # print(np.array([np.sum(frame_pred_results==0), np.sum(frame_pred_results==1), np.sum(frame_pred_results==2)]))\n","    # print(frame_pred)\n","\n","results_recall = recall_score(y_true, y_pred, average=None)\n","print(\"Test UAR(Unweighted Average Recall) :\", results_recall.mean())\n","\n","ConfusionMatrixDisplay(confusion_matrix(y_true, y_pred)).plot(cmap='Blues')"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"toc_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"modelenv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.6"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"f97432c16914304dbd818b138841742b9483a5a148ca981647dc7438178b3282"}}},"nbformat":4,"nbformat_minor":0}
